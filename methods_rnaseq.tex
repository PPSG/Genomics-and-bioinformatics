\documentclass[a4paper,11pt]{article}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{bbm}
\usepackage{amsmath}
\usepackage{indentfirst}
\usepackage{fullpage}
\usepackage{url}
\usepackage{graphicx}
\usepackage[center,footnotesize]{caption}
\usepackage[section]{placeins}
\usepackage{subfig}
\title{bbcflib's RNA-seq module: methods}
\date{October 24, 2011}
\author{Julien Delafontaine}
\begin{document}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%

The RNA-seq module takes as input BAM files resulting of the alignment of reads on the \emph{exonome}. It counts the number of times each reads mapped to each exon, and calculates the ratios RPK defined as follows:
$$ RPK = 1000\times \frac{\text{total number of reads on the exon}}{\text{exon length}} $$

Counts and RPK values will be globally called ``scores'' in the following.

The score of a gene is obtained by summing the respective scores of the exons it contains.

The score of transcripts is harder to calculate. Since an exon can be used to build several different transcripts, it is not clear to which transcript one should attribute a read mapping on that exon. One can map directly on the transcriptome; in this case, if a read maps to k different transcripts, usually a count of 1/k will be attributed to every of them. This way one can also reconstruct the scores on genes by summing the scores of all its transcripts. We prefer trying a mathematical approach of inferring transcripts expression from exons scores, in order to optimize the distribution of the reads among transcripts.

Note that junction reads are ``lost'' during the mapping on exons. For the moment they are not taken into account, although there may be a non-negligible quantity of them. Also they could help the redistribution of reads telling how many times at least a transcript was produced. Bowtie can save them into a separate BAM file that one could remap on the transcriptome to improve the results. Some biologists take it as a necessary condition to trust the program. Just to give an idea, from a typical experiment [KAP1 with MEF cells], we got 26\% of unaligned reads on the exonome, 45\% of which mapped to the transcriptome, meaning that there are about 12\% of reads from splice junctions. Moreover, about half of the remaining (6\% of total reads) mapped somewhere else in the genome.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Transcripts expression}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Problem formulation}
%-------------------------------

Suppose a gene $G$ possesses $n$ exons $E_1$,\ldots,$E_n$. There can be at most $m = \sum_{k=1}^n {n \choose k} = 2^{n}-1$ alternative transcripts, say $T_1$,\ldots,$T_{m}$. Call $e_1$,\ldots,$e_n$ the (known) scores of exons, and $t_1$,\ldots,$t_{m}$ the (unknown) scores of transcripts. For each transcript $T_i$, define $t_{ij}$ as the score of the part of the transcript corresponding to exon $E_j$, so that $t_i = t_{i1} + \ldots + t_{1n} = \sum_{k=0}^n I_{ik} \cdot t_{ik}$, where $I_{ik} = 1$ if transcript $T_i$ contains exon $E_k$, 0 otherwise.

Conversely we have $e_j = \sum_{k=1}^{m} I_{kj} \cdot t_{kj}$, $\forall j$. In matrix form,
$$
\begin{pmatrix}
e_1 \\ \vdots \\ e_n
\end{pmatrix}
=
\begin{pmatrix}
I_{11} & \cdots & I_{m1} & 0 & \cdots &   &      & \cdots & 0 \\
\vdots & &&&&&&& \vdots \\
0      & \cdots &        &   & \cdots & 0 &I_{1n} & \cdots & I_{mn}
\end{pmatrix}
\begin{pmatrix}
t_{11} \\ t_{21} \\ \vdots \\ t_{m,n-1} \\t_{mn}
\end{pmatrix}
$$

This is equivalent to just equally distribute the score of each read over the overlapping transcripts (what some usual alignment programs do), which is wrong because all parts of a same transcript must be equally transcribed. 

One can solve
$$
\begin{pmatrix}
e_1 \\ \vdots \\ e_n
\end{pmatrix}
=
\begin{pmatrix}
I_{11} & \cdots & I_{m1} \\
\vdots &        & \vdots \\
I_{1n} & \cdots & I_{mn}
\end{pmatrix}
\begin{pmatrix}
\bar{t_1} \\ \vdots \\ \bar{t_m}
\end{pmatrix},
$$
and then multiply $\bar{t_1},\ldots,\bar{t_m}$ by the number of exons each transcript contains, to obtain the RPK values for $t_1,\ldots,t_m$. This method would only hold for count data if all exons had the same length, but typically it is very variable. RPK values by definition are normalized with respect to the length of the exons.

Analyses of count or RPK data are quite different. To get counts as well, we consider the relative sizes of the different parts of a transcript and include this information in the matrix instead of binary values. For a given transcript $T_i$ with $t_{i1} \neq 0$, we have $t_i = t_{i1} + \ldots + t_{1n} = t_{i1} + \alpha_{i2} t_{i1} + \ldots + \alpha_{in} t_{i1}$. Defining $\bar{t_i} := t_{i,min\{j|E_j\in T_i\}}$, the linear system then becomes 

$$
\begin{pmatrix}
e_1 \\ \vdots \\ e_n
\end{pmatrix}
=
\begin{pmatrix}
I_{11} & \alpha_{21}I_{21} &\cdots & \alpha_{m1}I_{m1} \\
\vdots &                   &       & \vdots \\
I_{1n} & \alpha_{2n}I_{2n} &\cdots & \alpha_{m-1,n}I_{mn}
\end{pmatrix}
\begin{pmatrix}
\bar{t_1} \\ \vdots \\ \bar{t_m}
\end{pmatrix},
$$

Calling $E = (e_1, \ldots, e_n)^T$, $T = (\bar{t_{1}},\ldots,\bar{t_{m}})^T$, and $M$ the matrix in the middle, one has to solve for T the system of linear equations $E = MT$. Usually M will not be invertible, and m is greater than n, so the solution can only be an approximation. The problem becomes to solve
$$ \min_T ||E-MT||_2^2 $$
One can show that the optimal solution is given by the Moore-Penrose \emph{pseudo-inverse} of M, as follows.

\subsection{Pseudo-inverse}
%--------------------------

Let $M = UDV^T$ be the singular value decomposition of the $n\times m$ matrix $M$. $U$ is $n\times n$ unitary, $D$ is $n\times m$ diagonal, and $V$ is $m\times m$ unitary. $D$ contains the singular values of $M$ on its diagonal left block, and zeros on the right - if $m>n$ - or at the bottom - if $n>m$.
Then the matrix $M^{+} = V(D^{-1})^T U^T$ is called the pseudo-inverse of $M$, and $\tilde{T} = M^{+}E$ is the optimal solution of our problem, i.e. $\forall x, \; ||E-Mx||_2 \ge ||E-M\tilde{T}||_2$.

The relative error on $T$ is then given by 
%tilde{T} = M^{+}E = M^{+}MT \Rightarrow \tilde{T}-T = (M^{+}M-I_m)T $$
%$$ \Rightarrow \frac{||\tilde{T}-T||}{||T||} = ||M^{+}M-I_m|| $$
$$ ... $$
%In the case of counts, every entry in $E$ or $T$ is a number of reads, and $M$ is binary, so to obtain the error as a number of reads, I suggest using the norm 1 in the expression above. It is then easily comparable to the total number of reads, which is given by the norm 1 of $E$.

This method is guaranteed by some theorem to converge to the global minimum. However, it arises a very annoying issue: $\tilde{T}$ can have - often has - negative components, which are incompatible with the notion of counts or RPK (on the contrary, the fact that components of $\tilde{T}$ are not integers is not an issue).

\subsection{Non-negative least-squares}
%--------------------------------------

Adding a constraint of positiveness on the scores, the problem becomes
$$ \min_T ||E-MT||_2^2 \quad \text{, with constraint} \quad T \geq 0 $$
This can be solved by Alternative Nonnegative Least-Squares (ANLS). This kind of problem occurred rather recently in applications, and faster algorithms are still under development. Most of them depend a lot on initialization and insure to converge to a \emph{local} minimum only. Note that a local minimum can be sufficient for most applications (?).

For our particular case, we used a Python equivalent of Matlab's \texttt{lsqnonneg} function [\url{http://diffusion-mri.googlecode.com/svn/trunk/Python/lsqnonneg.py}], itself inspired by an algorithm of Lawson and Hanson [C.L. Lawson and R.J. Hanson, Solving Least-Squares Problems, Prentice-Hall, 1974, ch.23, p.161].

\subsection{Analysis}
%....................

\subsubsection{Error size}
Since we are trying distribute the exon counts among transcripts, the sum of scores over all exons in a gene should be approximately the sum over all its transcripts. 
The relevance of the least-squares approach is given by the differences $||E-MT||_2$. 
The rank of $M$ is bounded by $\min(n,m)$. Usually, there are less alternative transcripts than exons ($m<n$). This is equivalent to project - when estimating $M^{+}E$ - $n$-dimensional data onto an $m$-dimensional subspace. Therefore, scores on transcripts can be only inferior to exon scores. But for usual analyses that consider ratios between different conditions, we can hope that ratios (therefore differentially expressed transcripts) are maintained. 

A typical experiment [still KAP1 with MEF cells] lead to the following results.

The sum of negative components generated by the pseudo-inverse solution accounts for 16\% of the total counts (6\% of RPK) on transcripts.

The ratio between the total exon RPK and transcript RPK with NNLS is about 93\% - so 7\% of the initial counts are lost.

Surprisingly, the size of least-squares errors are not correlated with the ratio $n/m$.

The unconstrained least-squares problem is the maximum likelihood estimator for linear regression of \emph{normally distributed} data. Count data must use different models. Weighted least-squares applied to the exponential of our data (?) correspond to the generalized linear model we want to apply for differential expression analysis. However we believe that the NNLS solution is equivalent.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{GLM analysis module}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Encouraged by an article showing the comparison between different kinds of analysis modules [ref], we chose to replace the \texttt{R} package \texttt{DESeq} by a Generalized Linear Model (GLM), i.e. a non-linear regression model. The idea is to take into account the effect of the different parameters that define each of the different conditions, instead of only computing the ratios between scores in one condition and another. Since our observations (counts) seem to have a negative binomial distribution [ref], a standard regression is not appropriate.

A typical output of the RNA-seq module is a tab-delimited file of the form

\vspace{0.5 cm}
\begin{tabular}{lllll}
\textbf{FeatureName} & \textbf{Group1.1} & \textbf{Group1.2} & \textbf{Group2.1} & \ldots \\
Gene1       & 23       & 24       & 48       & \ldots \\
Gene2       & 11       & 11       & 18       & \ldots \\
\ldots
\end{tabular}
\vspace{0.5 cm}

Each numeric column is a different sample, some are replicates from the same experimental conditions. Each line represents a different feature (gene, exon, or transcript). We build a different GLM for each feature.

\subsection{Design}
The design matrix indicates which combination of parameters defines which condition. An example of design matrix could be

\vspace{0.5 cm}
\begin{tabular}{lllll}
             & \textbf{Group1} & \textbf{Group2} & \textbf{Group3}\\
Temperature  & 40       & 40       & 60 \\
Treatment    & 1        & 0        & 1  
\end{tabular}
\vspace{0.5 cm}

\subsection{Formulation of the GLM}

A regression model tries to explain a response variable $Y$ by covariates $X_1,X_2,\ldots$. For instance, the normal linear model is defined as $ Y = X\beta + \epsilon$, where $Y \sim N(X\beta,\sigma^2)$, $\beta$ is a vector of parameters to estimate, and $\epsilon \sim N(0,\sigma^2)$.

Let us take one of our features, say $f$. Our response variable $Y$ is the score vector of $f$ in $d$ different conditions:
$$ Y = (f_1,\ldots,f_d)^T $$
Our covariates are the parameters that determine our conditions, e.g. temperature, treatment, a.s.o. The matrix $X$ thus corresponds to the design matrix defined previously.

A GLM is determinate by the distribution of $Y$, and a \emph{link function} $g$ that connects the mean of $Y$, $\mu$, and the linear term:
$$ \mu = g(X\beta) $$
Once chosen the distribution of $Y$, one must choose a link function that maps the domain of $Y$ to that of $X$. In particular there is a unique \emph{canonical} link function that guarantees the existence of a minimal sufficient statistic for $\beta$, and that makes more sense with distributions of the exponential family (such as negative binomial \emph{only if the dispersion parameter in known and constant}). In the negative binomial case, it is $\log(\frac{\mu}{\mu+\theta})$, but is rarely used. One usually prefers the logarithm. Square root or even identity link functions are also supported in \texttt{R}.


\subsection{Contrasts}
The contrasts matrix indicates which tests we want to perform. An example contrasts matrix looks like
$$  $$

\subsection{Interpretation of the results}
The p-value associated to each feature in each group is the result of a test of the null hypothesis $\beta=0$ for the corresponding covariate. A small p-value means that the coefficient accounts for a non-negligible part of the total variance.

\subsection{Comparison with other methods}
- with DESeq
- ...

\end{document}
